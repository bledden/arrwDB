"""
Integration tests for metadata filtering functionality.

Tests the complete metadata filtering flow from API endpoint through
service layer to vector store, using real data and embeddings.
"""

import os
import tempfile
from pathlib import Path

import pytest
from fastapi.testclient import TestClient

from app.api.dependencies import get_library_repository
from app.api.main import app
from infrastructure.repositories.library_repository import LibraryRepository


@pytest.fixture(scope="session", autouse=True)
def check_api_key():
    """Ensure COHERE_API_KEY is set before running integration tests."""
    if not os.getenv("COHERE_API_KEY"):
        pytest.skip("COHERE_API_KEY environment variable not set")


@pytest.fixture
def test_repository():
    """Create a test repository with temporary directory for isolation."""
    with tempfile.TemporaryDirectory() as tmpdir:
        repo = LibraryRepository(Path(tmpdir))
        yield repo


@pytest.fixture
def client(test_repository):
    """
    Create a test client with dependency overrides.

    Only overrides the repository to use a temporary directory for test isolation.
    All other components (embedding service, indexes, etc.) use real implementations.
    """
    app.dependency_overrides[get_library_repository] = lambda: test_repository

    client = TestClient(app)
    yield client

    # Clean up overrides
    app.dependency_overrides.clear()


@pytest.fixture
def library_with_documents(client):
    """
    Create a library with multiple documents for filtering tests.

    Creates 3 documents with different texts.
    Note: chunk metadata (page_number, chunk_index) is auto-generated by the API.
    """
    # Create library
    create_lib = {
        "name": "Filter Test Library",
        "description": "Library for metadata filtering tests",
        "index_type": "brute_force",
    }
    response = client.post("/v1/libraries", json=create_lib)
    assert response.status_code == 201
    library_id = response.json()["id"]

    # Document 1: Machine learning content (5 chunks)
    doc1_request = {
        "title": "ML Basics",
        "texts": [
            "Machine learning is transforming technology and business operations.",
            "Supervised learning uses labeled data to train predictive models.",
            "Unsupervised learning finds patterns in unlabeled data automatically.",
            "Deep learning uses neural networks with multiple hidden layers.",
            "Reinforcement learning trains agents through reward and punishment.",
        ],
        "author": "Alice Smith",
        "tags": ["machine-learning", "ai"],
    }

    response = client.post(
        f"/v1/libraries/{library_id}/documents",
        json=doc1_request,
    )
    assert response.status_code == 201
    doc1_id = response.json()["id"]

    # Document 2: Deep learning content (3 chunks)
    doc2_request = {
        "title": "Deep Learning Guide",
        "texts": [
            "Deep learning neural networks learn hierarchical representations of data.",
            "Convolutional neural networks excel at image recognition and computer vision.",
            "Recurrent neural networks process sequential data like text and time series.",
        ],
        "author": "Bob Jones",
        "tags": ["deep-learning", "neural-networks"],
    }

    response = client.post(
        f"/v1/libraries/{library_id}/documents",
        json=doc2_request,
    )
    assert response.status_code == 201
    doc2_id = response.json()["id"]

    # Document 3: NLP content (4 chunks)
    doc3_request = {
        "title": "NLP Fundamentals",
        "texts": [
            "Natural language processing enables machines to understand human language.",
            "Tokenization breaks text into words or subword units for processing.",
            "Word embeddings represent words as dense vectors capturing semantic meaning.",
            "Transformers use attention mechanisms to process text in parallel efficiently.",
        ],
        "author": "Alice Smith",
        "tags": ["nlp", "language"],
    }

    response = client.post(
        f"/v1/libraries/{library_id}/documents",
        json=doc3_request,
    )
    assert response.status_code == 201
    doc3_id = response.json()["id"]

    return {
        "library_id": library_id,
        "doc1_id": doc1_id,
        "doc2_id": doc2_id,
        "doc3_id": doc3_id,
        "total_chunks": 12,
    }


@pytest.mark.integration
class TestMetadataFilteringBasics:
    """Test basic metadata filtering operations."""

    def test_search_with_single_filter_eq(self, client, library_with_documents):
        """Test filtering with single equality filter on chunk_index."""
        library_id = library_with_documents["library_id"]

        # Filter for chunks with chunk_index == 0 (first chunk of each document)
        request = {
            "query": "machine learning",
            "k": 10,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "eq", "value": 0}
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should get first chunks from documents (at least 1)
        assert data["total_results"] >= 1

        # All results should have chunk_index == 0
        for result in data["results"]:
            assert result["chunk"]["metadata"]["chunk_index"] == 0

    def test_search_with_single_filter_gte(self, client, library_with_documents):
        """Test filtering with >= operator on chunk_index."""
        library_id = library_with_documents["library_id"]

        # Filter for chunks with chunk_index >= 2
        request = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "gte", "value": 2}
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should get some chunks with index >= 2
        assert data["total_results"] >= 1

        # All results should have chunk_index >= 2
        for result in data["results"]:
            chunk_idx = result["chunk"]["metadata"]["chunk_index"]
            assert chunk_idx >= 2

    def test_search_with_single_filter_lt(self, client, library_with_documents):
        """Test filtering with < operator on chunk_index."""
        library_id = library_with_documents["library_id"]

        # Filter for chunks with chunk_index < 2
        request = {
            "query": "machine learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "lt", "value": 2}
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should get some results
        assert data["total_results"] >= 1

        # All results should have chunk_index < 2
        for result in data["results"]:
            chunk_idx = result["chunk"]["metadata"]["chunk_index"]
            assert chunk_idx < 2


@pytest.mark.integration
class TestMetadataFilteringMultiple:
    """Test multiple filters with AND logic."""

    def test_search_with_multiple_filters_and_logic(self, client, library_with_documents):
        """Test that multiple filters use AND logic."""
        library_id = library_with_documents["library_id"]

        # Filter for chunks with chunk_index >= 1 AND chunk_index <= 2
        # This tests that both conditions must be satisfied (AND logic)
        request = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "gte", "value": 1},
                {"field": "chunk_index", "operator": "lte", "value": 2},
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should get some results matching both conditions
        assert data["total_results"] >= 1

        # All results should match BOTH conditions (chunk_index in [1, 2])
        for result in data["results"]:
            chunk_idx = result["chunk"]["metadata"]["chunk_index"]
            assert 1 <= chunk_idx <= 2

    def test_search_with_restrictive_filters(self, client, library_with_documents):
        """Test that restrictive filters return fewer results."""
        library_id = library_with_documents["library_id"]

        # First search without filters
        request_no_filter = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request_no_filter,
        )
        assert response.status_code == 200
        total_no_filter = response.json()["total_results"]

        # Now search with restrictive filter
        request_with_filter = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "eq", "value": 0},
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request_with_filter,
        )
        assert response.status_code == 200
        total_with_filter = response.json()["total_results"]

        # With filter should return fewer results
        assert total_with_filter <= total_no_filter

        # All results should have chunk_index == 0
        for result in response.json()["results"]:
            assert result["chunk"]["metadata"]["chunk_index"] == 0


@pytest.mark.integration
class TestMetadataFilteringOperators:
    """Test different filter operators."""

    def test_filter_with_ne_operator(self, client, library_with_documents):
        """Test != operator on chunk_index."""
        library_id = library_with_documents["library_id"]

        # Filter for chunks NOT from chunk_index 0
        request = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "ne", "value": 0},
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should have some results
        assert data["total_results"] >= 1

        # None should have chunk_index == 0
        for result in data["results"]:
            assert result["chunk"]["metadata"]["chunk_index"] != 0

    def test_filter_with_in_operator(self, client, library_with_documents):
        """Test 'in' operator with list of values."""
        library_id = library_with_documents["library_id"]

        # Filter for specific chunk indices
        request = {
            "query": "learning",
            "k": 20,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "in", "value": [0, 1]},
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should have results from those specific indices
        assert data["total_results"] >= 1

        # All results should have chunk_index in [0, 1]
        for result in data["results"]:
            chunk_idx = result["chunk"]["metadata"]["chunk_index"]
            assert chunk_idx in [0, 1]


@pytest.mark.integration
class TestMetadataFilteringEdgeCases:
    """Test edge cases for metadata filtering."""

    def test_search_with_no_filters(self, client, library_with_documents):
        """Test that empty filters list works like normal search."""
        library_id = library_with_documents["library_id"]

        request = {
            "query": "machine learning",
            "k": 10,
            "metadata_filters": [],  # No filters
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should return results like normal search
        assert data["total_results"] > 0
        assert len(data["results"]) <= 10

    def test_search_with_filter_no_matches(self, client, library_with_documents):
        """Test filter that matches no chunks."""
        library_id = library_with_documents["library_id"]

        # Filter for chunk_index that doesn't exist (we only have 0-4)
        request = {
            "query": "learning",
            "k": 10,
            "metadata_filters": [
                {"field": "chunk_index", "operator": "eq", "value": 999},
            ],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should return 0 results
        assert data["total_results"] == 0
        assert len(data["results"]) == 0

    def test_search_with_k_smaller_than_results(self, client, library_with_documents):
        """Test that k parameter limits results correctly."""
        library_id = library_with_documents["library_id"]

        # Request only 2 results
        request = {
            "query": "learning",
            "k": 2,
            "metadata_filters": [],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Should return at most 2 results
        assert len(data["results"]) <= 2

    def test_search_with_include_embeddings_flag(self, client, library_with_documents):
        """Test that include_embeddings flag works with filtering."""
        library_id = library_with_documents["library_id"]

        request = {
            "query": "machine learning",
            "k": 5,
            "metadata_filters": [],
        }

        # Without embeddings
        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered?include_embeddings=false",
            json=request,
        )
        assert response.status_code == 200
        data = response.json()

        # Should not have embeddings in chunk
        if len(data["results"]) > 0:
            assert "embedding" not in data["results"][0]["chunk"]

        # With embeddings
        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered?include_embeddings=true",
            json=request,
        )
        assert response.status_code == 200
        data = response.json()

        # Should have embeddings in chunk
        if len(data["results"]) > 0:
            assert "embedding" in data["results"][0]["chunk"]
            assert len(data["results"][0]["chunk"]["embedding"]) > 0


@pytest.mark.integration
class TestMetadataFilteringResponseFormat:
    """Test response format matches regular search."""

    def test_response_includes_required_fields(self, client, library_with_documents):
        """Test that response has all required fields."""
        library_id = library_with_documents["library_id"]

        request = {
            "query": "learning",
            "k": 5,
            "metadata_filters": [],
        }

        response = client.post(
            f"/v1/libraries/{library_id}/search/filtered",
            json=request,
        )

        assert response.status_code == 200
        data = response.json()

        # Check top-level fields
        assert "results" in data
        assert "query_time_ms" in data
        assert "total_results" in data

        # Check result fields
        if len(data["results"]) > 0:
            result = data["results"][0]
            assert "chunk" in result
            assert "distance" in result
            assert "document_id" in result
            assert "document_title" in result

            # Check chunk fields
            chunk = result["chunk"]
            assert "id" in chunk
            assert "text" in chunk
            assert "metadata" in chunk

            # Check chunk metadata fields
            metadata = chunk["metadata"]
            assert "created_at" in metadata
            assert "chunk_index" in metadata
            assert "source_document_id" in metadata


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
